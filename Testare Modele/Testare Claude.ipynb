{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e2e48-52f3-41b7-a1bf-60291dc14da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import anthropic\n",
    "\n",
    "    # Cautarea raspunsului corect\n",
    "def extrage_litera_raspuns(text):\n",
    "    pattern = r\"[Rr]ă?s?puns\\s+corect\\s*:\\s*([a-fA-F])\\b\"\n",
    "    match = re.search(pattern, text, flags=re.IGNORECASE | re.MULTILINE)\n",
    "    if not match:\n",
    "        match = re.search(r\"\\\\boxed\\{([a-fA-F])\\}\", text)\n",
    "    return match.group(1).lower() if match else \"?\"\n",
    "\n",
    "    # Incarcare shots\n",
    "def incarca_shots(cale_fisier):\n",
    "    if not cale_fisier:\n",
    "        return \"\"\n",
    "    with open(cale_fisier, \"r\", encoding=\"utf-8\") as f:\n",
    "        shots_data = [json.loads(line) for line in f]\n",
    "    exemple = []\n",
    "    for ex in shots_data:\n",
    "        messages = ex.get(\"messages\", [])\n",
    "        user_msg = next((m[\"content\"] for m in messages if m[\"role\"].lower() == \"user\"), \"\")\n",
    "        bot_msg = next((m[\"content\"] for m in messages if m[\"role\"].lower() in {\"chatbot\", \"assistant\"}), \"\")\n",
    "        if user_msg and bot_msg:\n",
    "            exemple.append(f\"{user_msg.strip()}\\n{bot_msg.strip()}\")\n",
    "    return \"\\n\\n\".join(exemple)\n",
    "\n",
    "    # Functia de evaluare a modelului\n",
    "def evalueaza_modelul_chat_claude(test_file_path, model_name, api_key, label=\"Set\", output_csv=True, shots_file=None, silent=False):\n",
    "    client = anthropic.Anthropic(api_key=api_key)\n",
    "    instructiuni = \"\\n\\nInstrucțiuni: Alege litera răspunsului corect (a–f). Răspunde exact la ultima problemă în formatul: Răspuns corect: x\"\n",
    "    context_fewshot = incarca_shots(shots_file)\n",
    "\n",
    "    with open(test_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        test_data = [json.loads(line) for line in f]\n",
    "\n",
    "    user_prompts = []\n",
    "    full_prompts = []\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "    outputs_raw = []\n",
    "\n",
    "    for idx, sample in enumerate(test_data):\n",
    "        messages = sample.get(\"messages\", [])\n",
    "        user_msg = next((m[\"content\"] for m in messages if m[\"role\"].lower() == \"user\"), \"\")\n",
    "        bot_msg = next((m[\"content\"] for m in messages if m[\"role\"].lower() in {\"chatbot\", \"assistant\"}), \"\")\n",
    "        full_prompt = f\"{context_fewshot}\\n\\n{user_msg.strip()}{instructiuni}\" if context_fewshot else f\"{user_msg.strip()}{instructiuni}\"\n",
    "\n",
    "        if idx == 0:\n",
    "            print(\"\\n=== Exemplu prompt complet trimis la model (primul) ===\\n\")\n",
    "            print(full_prompt)\n",
    "            print(\"\\n=== Sfârșit prompt ===\\n\")\n",
    "\n",
    "        full_prompts.append(full_prompt)\n",
    "        user_prompts.append(user_msg.strip())\n",
    "        true_labels.append(extrage_litera_raspuns(bot_msg))\n",
    "\n",
    "    for prompt in tqdm(full_prompts, desc=f\"Evaluare {label}\"):\n",
    "        try:\n",
    "            response = client.messages.create(\n",
    "                model=model_name,\n",
    "                max_tokens=1024,\n",
    "                temperature=0,\n",
    "                system=\"Ești un asistent care rezolvă exerciții de matematică pentru admitere.\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            output = response.content[0].text.strip()\n",
    "            predicted = extrage_litera_raspuns(output)\n",
    "        except Exception as e:\n",
    "            output = \"??\"\n",
    "            predicted = \"?\"\n",
    "            if not silent:\n",
    "                print(\"Eroare:\", e)\n",
    "\n",
    "        outputs_raw.append(output)\n",
    "        predictions.append(predicted)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"prompt\": user_prompts,\n",
    "        \"true\": true_labels,\n",
    "        \"pred\": predictions,\n",
    "        \"output\": outputs_raw\n",
    "    })\n",
    "    df[\"correct\"] = df[\"true\"] == df[\"pred\"]\n",
    "\n",
    "    if not silent:\n",
    "        acc = accuracy_score(df[\"true\"], df[\"pred\"])\n",
    "        print(f\"\\nAcuratețe ({label}): {acc:.2%}\")\n",
    "        print(\"\\n=== Raport ===\")\n",
    "        print(classification_report(df[\"true\"], df[\"pred\"], zero_division=0))\n",
    "        print(\"Distribuție predicții:\", dict(Counter(df[\"pred\"])))\n",
    "\n",
    "    if output_csv:\n",
    "        csv_name = f\"rezultate_{label.lower().replace(' ', '_')}.csv\"\n",
    "        df.to_csv(csv_name, index=False, encoding=\"utf-8-sig\")\n",
    "        if not silent:\n",
    "            print(f\"Fișier CSV salvat: {csv_name}\")\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3272954f-ca56-4564-bb05-4e56c1a6ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setari\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"Chei.env\")\n",
    "API_KEY = os.getenv(\"CLAUDE_KEY\")\n",
    "MODEL_NAME = \"claude-3-opus-20240229\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c10795-f659-436c-9c5b-15741bc9729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testare pe setul de test\n",
    "evalueaza_modelul_chat_claude(\n",
    "    test_file_path=\"fine_tune_test_full.jsonl\",\n",
    "    model_name=MODEL_NAME,\n",
    "    api_key=API_KEY,\n",
    "    label=\"Zero-shot Test\",\n",
    "    shots_file=None\n",
    ")\n",
    "# Label - influentez numele fisierelor la iesire\n",
    "# shots-file = None sau fisierul care are shots-urile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc6c3f-2916-4f38-b60e-779a53726dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testare pe setul de validare\n",
    "evalueaza_modelul_chat_claude(\n",
    "    test_file_path=\"fine_tune_validation_full.jsonl\",\n",
    "    model_name=MODEL_NAME,\n",
    "    api_key=API_KEY,\n",
    "    label=\"Zero-shot Validare\",\n",
    "    shots_file=None\n",
    ")\n",
    "# Label - influentez numele fisierelor la iesire\n",
    "# shots-file = None sau fisierul care are shots-urile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400cc8d6-c162-41ae-a027-84144e317973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafic set de testare\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"rezultate_few-shot_test.csv\")\n",
    "df[\"correct\"] = df[\"true\"] == df[\"pred\"]\n",
    "\n",
    "label_counts = df[\"true\"].value_counts().sort_index()\n",
    "correct_counts = df[df[\"correct\"]][\"true\"].value_counts().sort_index()\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(label_counts.index, label_counts.values, alpha=0.5, label=\"Total\")\n",
    "plt.bar(correct_counts.index, correct_counts.values, alpha=0.8, label=\"Corecte\")\n",
    "plt.title(\"Performanță model - set Test\")\n",
    "plt.xlabel(\"Variantă de răspuns\")\n",
    "plt.ylabel(\"Număr\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df6cfa1-97f1-45ca-9a05-f1528f274df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafic set de validare\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"rezultate_few-shot_validare.csv\")\n",
    "df[\"correct\"] = df[\"true\"] == df[\"pred\"]\n",
    "\n",
    "label_counts = df[\"true\"].value_counts().sort_index()\n",
    "correct_counts = df[df[\"correct\"]][\"true\"].value_counts().sort_index()\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(label_counts.index, label_counts.values, alpha=0.5, label=\"Total\")\n",
    "plt.bar(correct_counts.index, correct_counts.values, alpha=0.8, label=\"Corecte\")\n",
    "plt.title(\"Performanță model - set Validare\")\n",
    "plt.xlabel(\"Variantă de răspuns\")\n",
    "plt.ylabel(\"Număr\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21356421-968a-417b-af5b-f1e514e74c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafic cand nu putea sa aleaga unul dintre variantele de raspuns - testare\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"rezultate_zero-shot-test.csv\")\n",
    "df[\"correct\"] = df[\"true\"] == df[\"pred\"]\n",
    "\n",
    "# Definim toate literele a–f si ?\n",
    "litere = list(\"abcdef\")\n",
    "toate_literele = litere + [\"?\"]\n",
    "\n",
    "# Numar total de intrebari pentru fiecare raspuns corect (true)\n",
    "true_counts = df[\"true\"].value_counts().reindex(litere, fill_value=0)\n",
    "\n",
    "# Numar de predictii corecte (true == pred)\n",
    "correct_counts = df[df[\"correct\"]][\"true\"].value_counts().reindex(litere, fill_value=0)\n",
    "\n",
    "# Numar total de predictii cu `?`\n",
    "num_unknown = (df[\"pred\"] == \"?\").sum()\n",
    "\n",
    "# Pregatire date extinse cu ?\n",
    "true_counts_ext = pd.concat([true_counts, pd.Series({\"?\": 0})])\n",
    "correct_counts_ext = pd.concat([correct_counts, pd.Series({\"?\": 0})])\n",
    "total_counts_ext = true_counts_ext.copy()\n",
    "total_counts_ext[\"?\"] = num_unknown\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.bar(total_counts_ext.index, total_counts_ext.values, alpha=0.5, label=\"Total\")\n",
    "plt.bar(correct_counts_ext.index, correct_counts_ext.values, alpha=0.8, label=\"Corecte\")\n",
    "plt.title(\"Performanță model – Test\")\n",
    "plt.xlabel(\"Variantă de răspuns (a–f + ?)\")\n",
    "plt.ylabel(\"Număr de întrebări\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18575e34-47ec-4c5a-ab9e-1181a7137e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafic cand nu putea sa aleaga unul dintre variantele de raspuns - validare\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"rezultate_zero-shot-validare.csv\")\n",
    "df[\"correct\"] = df[\"true\"] == df[\"pred\"]\n",
    "\n",
    "# Definim toate literele a–f si ?\n",
    "litere = list(\"abcdef\")\n",
    "toate_literele = litere + [\"?\"]\n",
    "\n",
    "# Numar total de intrebari pentru fiecare raspuns corect (true)\n",
    "true_counts = df[\"true\"].value_counts().reindex(litere, fill_value=0)\n",
    "\n",
    "# Numar de predictii corecte (true == pred)\n",
    "correct_counts = df[df[\"correct\"]][\"true\"].value_counts().reindex(litere, fill_value=0)\n",
    "\n",
    "# Numar total de predictii cu `?`\n",
    "num_unknown = (df[\"pred\"] == \"?\").sum()\n",
    "\n",
    "# Pregatire date extinse cu ?\n",
    "true_counts_ext = pd.concat([true_counts, pd.Series({\"?\": 0})])\n",
    "correct_counts_ext = pd.concat([correct_counts, pd.Series({\"?\": 0})])\n",
    "total_counts_ext = true_counts_ext.copy()\n",
    "total_counts_ext[\"?\"] = num_unknown\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.bar(total_counts_ext.index, total_counts_ext.values, alpha=0.5, label=\"Total\")\n",
    "plt.bar(correct_counts_ext.index, correct_counts_ext.values, alpha=0.8, label=\"Corecte\")\n",
    "plt.title(\"Performanță model – Test\")\n",
    "plt.xlabel(\"Variantă de răspuns (a–f + ?)\")\n",
    "plt.ylabel(\"Număr de întrebări\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e333ee-7309-49ff-9187-9b3e70a9c38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculez acuratetea pe dificultate pentru fiecare set\n",
    "import pandas as pd\n",
    "\n",
    "def calculeaza_acuratete_pe_dificultate(cale_csv, eticheta_set):\n",
    "    df = pd.read_csv(cale_csv)\n",
    "    df[\"dificultate\"] = df[\"prompt\"].str.extract(r\"\\d+\\.(?:\\d+)?([ABC])\\.\")\n",
    "    if \"correct\" not in df.columns:\n",
    "        df[\"correct\"] = df[\"true\"] == df[\"pred\"]\n",
    "    acuratete = df.groupby(\"dificultate\")[\"correct\"].mean().reset_index()\n",
    "    acuratete.columns = [\"Dificultate\", f\"Acuratețe {eticheta_set}\"]\n",
    "    return acuratete\n",
    "\n",
    "acuratete_test = calculeaza_acuratete_pe_dificultate(\"rezultate_zero-shot-test.csv\", \"Test\")\n",
    "acuratete_val  = calculeaza_acuratete_pe_dificultate(\"rezultate_zero-shot-validare.csv\", \"Validare\")\n",
    "\n",
    "df_comparatie = pd.merge(acuratete_test, acuratete_val, on=\"Dificultate\", how=\"outer\")\n",
    "print(df_comparatie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09fa4b1-a656-4d57-9e7b-92d331b465e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acuratete pe capitol pentru test\n",
    "df_test = pd.read_csv(\"rezultate_zero-shot-test.csv\")\n",
    "df_all = pd.read_csv(\"exercitii_extrase_structurat_rezolvari.csv\")\n",
    "df_test[\"id\"] = df_test[\"prompt\"].str.extract(r\"^(\\S+)\").iloc[:, 0].str.replace(r\"\\.$\", \"\", regex=True)\n",
    "df_test[\"id\"] = df_test[\"id\"].astype(str)\n",
    "df_all[\"id\"] = df_all[\"id\"].astype(str)\n",
    "df_merged = df_test.merge(df_all[[\"id\", \"capitol\"]], on=\"id\", how=\"left\")\n",
    "if \"correct\" not in df_merged.columns:\n",
    "    df_merged[\"correct\"] = df_merged[\"true\"] == df_merged[\"pred\"]\n",
    "accuracy_by_chapter = df_merged.groupby(\"capitol\")[\"correct\"].mean().reset_index()\n",
    "accuracy_by_chapter.columns = [\"Capitol\", \"Acuratețe\"]\n",
    "print(accuracy_by_chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7195e58-af5a-4cf8-a2f5-ce7da8560391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acuratete pe capitol pentru test\n",
    "df_test = pd.read_csv(\"rezultate_zero-shot-test.csv\")\n",
    "df_all = pd.read_csv(\"exercitii_extrase_structurat_rezolvari.csv\")\n",
    "\n",
    "df_test[\"id\"] = df_test[\"prompt\"].str.extract(r\"^(\\S+)\").iloc[:, 0].str.replace(r\"\\.$\", \"\", regex=True)\n",
    "df_test[\"id\"] = df_test[\"id\"].astype(str)\n",
    "df_all[\"id\"] = df_all[\"id\"].astype(str)\n",
    "df_merged = df_test.merge(df_all[[\"id\", \"capitol\"]], on=\"id\", how=\"left\")\n",
    "if \"correct\" not in df_merged.columns:\n",
    "    df_merged[\"correct\"] = df_merged[\"true\"] == df_merged[\"pred\"]\n",
    "\n",
    "accuracy_by_chapter = df_merged.groupby(\"capitol\")[\"correct\"].mean().reset_index()\n",
    "accuracy_by_chapter.columns = [\"Capitol\", \"Acuratețe\"]\n",
    "print(accuracy_by_chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007d66b4-08a5-4fdd-8287-54502c0aa1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acuratete pe capitol pentru validare\n",
    "df_validare = pd.read_csv(\"rezultate_zero-shot-validare.csv\")\n",
    "df_all = pd.read_csv(\"exercitii_extrase_structurat_rezolvari.csv\")\n",
    "\n",
    "df_validare[\"id\"] = df_validare[\"prompt\"].str.extract(r\"^(\\S+)\").iloc[:, 0].str.replace(r\"\\.$\", \"\", regex=True)\n",
    "df_validare[\"id\"] = df_validare[\"id\"].astype(str)\n",
    "df_all[\"id\"] = df_all[\"id\"].astype(str)\n",
    "df_merged = df_validare.merge(df_all[[\"id\", \"capitol\"]], on=\"id\", how=\"left\")\n",
    "if \"correct\" not in df_merged.columns:\n",
    "    df_merged[\"correct\"] = df_merged[\"true\"] == df_merged[\"pred\"]\n",
    "\n",
    "accuracy_by_chapter = df_merged.groupby(\"capitol\")[\"correct\"].mean().reset_index()\n",
    "accuracy_by_chapter.columns = [\"Capitol\", \"Acuratețe\"]\n",
    "print(accuracy_by_chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb3c2d7-d6e8-42f6-ae8f-15378ef91ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confuzie pentru testare\n",
    "df_test = pd.read_csv(\"rezultate_zero-shot-test.csv\")\n",
    "\n",
    "# Calculeaz matricea de confuzie\n",
    "cm = confusion_matrix(df_test[\"TRUE\"], df_test[\"pred\"], labels=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\",\"?\"])\n",
    "\n",
    "# Setari pentru grafic\n",
    "plt.figure(figsize=(4, 3.5))\n",
    "sns.set(style=\"white\", font_scale=0.9)\n",
    "\n",
    "# Heatmap\n",
    "ax = sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap=\"Blues\",\n",
    "    cbar=True,\n",
    "    linewidths=0.5,\n",
    "    linecolor=\"black\",\n",
    "    xticklabels=list(\"abcdef?\"),\n",
    "    yticklabels=list(\"abcdef?\"),\n",
    "    annot_kws={\"size\": 10, \"weight\": \"bold\", \"color\": \"black\"}\n",
    ")\n",
    "\n",
    "# Etichete si titlu\n",
    "ax.set_xlabel(\"Predicție\", fontsize=10)\n",
    "ax.set_ylabel(\"Adevărat\", fontsize=10)\n",
    "ax.set_title(\"Matrice de confuzie – set Test\", fontsize=11, weight=\"bold\")\n",
    "\n",
    "# Layout si salvare\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"matrice_confuzie_test.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2143d5-11ee-4787-a7fc-5f482f313c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confuzie pentru validare\n",
    "df_validare = pd.read_csv(\"rezultate_zero-shot-validare.csv\")\n",
    "\n",
    "# Calculeaz matricea de confuzie\n",
    "cm = confusion_matrix(df_validare[\"TRUE\"], df_validare[\"pred\"], labels=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\",\"?\"])\n",
    "\n",
    "# Setari pentru grafic\n",
    "plt.figure(figsize=(4, 3.5))\n",
    "sns.set(style=\"white\", font_scale=0.9)\n",
    "\n",
    "# Heatmap\n",
    "ax = sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap=\"Blues\",\n",
    "    cbar=True,\n",
    "    linewidths=0.5,\n",
    "    linecolor=\"black\",\n",
    "    xticklabels=list(\"abcdef?\"),\n",
    "    yticklabels=list(\"abcdef?\"),\n",
    "    annot_kws={\"size\": 10, \"weight\": \"bold\", \"color\": \"black\"}\n",
    ")\n",
    "\n",
    "# Etichete si titlu\n",
    "ax.set_xlabel(\"Predicție\", fontsize=10)\n",
    "ax.set_ylabel(\"Adevărat\", fontsize=10)\n",
    "ax.set_title(\"Matrice de confuzie – set Test\", fontsize=11, weight=\"bold\")\n",
    "\n",
    "# Layout si salvare\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"matrice_confuzie_test.png\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
