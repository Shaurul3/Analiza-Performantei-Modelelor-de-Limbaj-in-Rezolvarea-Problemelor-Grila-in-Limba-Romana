{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6844320c-be19-4e1c-a627-41a43c6206b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "    # Cautarea raspunsului corect\n",
    "def extrage_raspuns_corect(text):\n",
    "    match_latex = re.search(r\"\\\\boxed\\{\\s*([a-fA-F])\\s*\\}\", text)\n",
    "    if match_latex:\n",
    "        return match_latex.group(1).lower()\n",
    "\n",
    "    match_std = re.search(r\"[Rr]ăspuns\\s+(corect\\s*[:\\-]?\\s*)?([a-fA-F])\", text)\n",
    "    if match_std:\n",
    "        return match_std.group(2).lower()\n",
    "\n",
    "    return \"?\"\n",
    "\n",
    "    # Incarcare shots\n",
    "def incarca_shots(cale_fisier):\n",
    "    if not cale_fisier:\n",
    "        return []\n",
    "    with open(cale_fisier, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "    # Functia de evaluare a modelului\n",
    "def evalueaza_modelul_fireworks(test_file_path, model_name, api_key, label=\"Set\", output_csv=True, shots_file=None):\n",
    "    url = \"https://api.fireworks.ai/inference/v1/chat/completions\"\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    with open(test_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        test_data = [json.loads(line) for line in f]\n",
    "\n",
    "    shots_data = incarca_shots(shots_file)\n",
    "\n",
    "    # Pregatirea setului de date pt incarcare\n",
    "    prompts, gold, predictions, outputs_raw = [], [], [], []\n",
    "\n",
    "    # Rularea modelului  \n",
    "    for idx, sample in enumerate(tqdm(test_data, desc=f\"Evaluare {label}\")):\n",
    "        user_msg = next((m[\"content\"] for m in sample[\"messages\"] if m[\"role\"].lower() == \"user\"), \"\")\n",
    "        assistant_msg = next((m[\"content\"] for m in sample[\"messages\"] if m[\"role\"].lower() in {\"chatbot\", \"assistant\"}), \"\")\n",
    "        true_answer = extrage_raspuns_corect(assistant_msg)\n",
    "        gold.append(true_answer)\n",
    "\n",
    "        full_prompt = []\n",
    "        for shot in shots_data:\n",
    "            shot_user = next((m[\"content\"] for m in shot[\"messages\"] if m[\"role\"].lower() == \"user\"), \"\")\n",
    "            shot_assistant = next((m[\"content\"] for m in shot[\"messages\"] if m[\"role\"].lower() in {\"chatbot\", \"assistant\"}), \"\")\n",
    "            full_prompt.append({\"role\": \"user\", \"content\": shot_user})\n",
    "            full_prompt.append({\"role\": \"assistant\", \"content\": shot_assistant})\n",
    "\n",
    "        task_prompt = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_msg.strip() + \"\\n\\nInstrucțiuni: Alege litera răspunsului corect (a–f). Răspunde exact în formatul: Răspuns corect: x\"\n",
    "        }\n",
    "        full_prompt.append(task_prompt)\n",
    "\n",
    "        if idx == 0:\n",
    "            print(\"\\n=== Prompt complet trimis (exemplul 1) ===\")\n",
    "            for m in full_prompt:\n",
    "                print(f\"[{m['role'].upper()}] {m['content']}\\n\")\n",
    "            print(\"=== Sfârșit prompt ===\\n\")\n",
    "\n",
    "        prompts.append(user_msg)\n",
    "\n",
    "        try:\n",
    "            payload = {\n",
    "                \"model\": model_name,\n",
    "                \"max_tokens\": 4096,\n",
    "                \"temperature\": 0,\n",
    "                \"top_p\": 1,\n",
    "                \"top_k\": 40,\n",
    "                \"presence_penalty\": 0,\n",
    "                \"frequency_penalty\": 0,\n",
    "                \"messages\": full_prompt\n",
    "            }\n",
    "\n",
    "            response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "            response_json = response.json()\n",
    "            reply = response_json[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            predicted = extrage_raspuns_corect(reply)\n",
    "        except Exception as e:\n",
    "            print(\"Eroare:\", e)\n",
    "            reply = \"Eroare\"\n",
    "            predicted = \"?\"\n",
    "\n",
    "        predictions.append(predicted)\n",
    "        outputs_raw.append(reply)\n",
    "\n",
    "    # Extragerea tuturor informatiilor de la prompt si le aranjam \n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"prompt\": prompts,\n",
    "        \"raspuns_corect\": gold,\n",
    "        \"pred\": predictions,\n",
    "        \"output\": outputs_raw\n",
    "    })\n",
    "    df[\"correct\"] = df[\"raspuns_corect\"] == df[\"pred\"]\n",
    "    df[\"correct\"] = df[\"correct\"].map({True: \"TRUE\", False: \"FALSE\"})\n",
    "\n",
    "    # Date si rapoarte\n",
    "    acc = accuracy_score(df[\"raspuns_corect\"], df[\"pred\"])\n",
    "    print(f\"\\nAcuratețe ({label}): {acc:.2%}\")\n",
    "    print(\"\\n=== Raport ===\")\n",
    "    print(classification_report(df[\"raspuns_corect\"], df[\"pred\"], zero_division=0))\n",
    "\n",
    "    if output_csv:\n",
    "        csv_name = f\"rezultate_{label.lower().replace(' ', '_')}.csv\"\n",
    "        df.to_csv(csv_name, index=False, encoding=\"utf-8-sig\", quoting=1)\n",
    "        print(f\"Rezultatele au fost salvate în: {csv_name}\")\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa5f6ba-fc47-4293-a05a-7d9e10c3a30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setări\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"Chei.env\")\n",
    "API_KEY = os.getenv(\"FIREWORKS_KEY\")  # cheia ta OpenAI\n",
    "MODEL_NAME = \"accounts/fireworks/models/llama-v3p1-70b-instruct\"  # model: LLAMA, DEEPSEEK, .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4466f88-94f2-4bd9-8265-79a266c1b205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testare pe setul de test\n",
    "df = evalueaza_modelul_fireworks(\n",
    "    test_file_path=\"fine_tune_test_full.jsonl\",\n",
    "    model_name=MODEL_NAME,\n",
    "    api_key=API_KEY,\n",
    "    label=\"Few-shot-Test\",\n",
    "    shots_file=\"few-shots.jsonl\"\n",
    ")\n",
    "# Label - influentez numele fisierelor la iesire\n",
    "# shots-file = None sau fisierul care are shots-urile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4bbe3a-d5a3-487d-8798-b303e03c4588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testare pe setul de validare\n",
    "df = evalueaza_modelul_fireworks(\n",
    "    test_file_path=\"fine_tune_test_full.jsonl\",\n",
    "    model_name=MODEL_NAME,\n",
    "    api_key=API_KEY,\n",
    "    label=\"Few-shot-Test\",\n",
    "    shots_file=\"few-shots.jsonl\"\n",
    ")\n",
    "# Label - influentez numele fisierelor la iesire\n",
    "# shots-file = None sau fisierul care are shots-urile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4451ef-a2f3-4f84-8613-a97f445916c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generare grafic\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"rezultate_few-shot-test.csv\")\n",
    "\n",
    "df[\"correct\"] = df[\"raspuns_corect\"] == df[\"pred\"]\n",
    "\n",
    "label_counts = df[\"raspuns_corect\"].value_counts().sort_index()\n",
    "correct_counts = df[df[\"correct\"]][\"raspuns_corect\"].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(label_counts.index, label_counts.values, alpha=0.5, label=\"Total\")\n",
    "plt.bar(correct_counts.index, correct_counts.values, alpha=0.8, label=\"Corecte\")\n",
    "plt.title(\"Performanță model - set Test\")\n",
    "plt.xlabel(\"Variantă de răspuns\")\n",
    "plt.ylabel(\"Număr\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade08271-4f8b-4104-a92a-04e3d6bbe8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generare grafic\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"rezultate_few-shot-validation.csv\")\n",
    "\n",
    "df[\"correct\"] = df[\"raspuns_corect\"] == df[\"pred\"]\n",
    "\n",
    "label_counts = df[\"raspuns_corect\"].value_counts().sort_index()\n",
    "correct_counts = df[df[\"correct\"]][\"raspuns_corect\"].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(label_counts.index, label_counts.values, alpha=0.5, label=\"Total\")\n",
    "plt.bar(correct_counts.index, correct_counts.values, alpha=0.8, label=\"Corecte\")\n",
    "plt.title(\"Performanță model - set Validare\")\n",
    "plt.xlabel(\"Variantă de răspuns\")\n",
    "plt.ylabel(\"Număr\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9472dc1-5a91-453f-a707-d83ccd5581dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculez acuratetea pe dificultate pentru fiecare set\n",
    "import pandas as pd\n",
    "\n",
    "def calculeaza_acuratete_pe_dificultate(cale_csv, eticheta_set):\n",
    "    df = pd.read_csv(cale_csv)\n",
    "    df[\"dificultate\"] = df[\"prompt\"].str.extract(r\"\\d+\\.(?:\\d+)?([ABC])\\.\")\n",
    "    if \"correct\" not in df.columns:\n",
    "        df[\"correct\"] = df[\"raspuns_corect\"] == df[\"pred\"]\n",
    "    acuratete = df.groupby(\"dificultate\")[\"correct\"].mean().reset_index()\n",
    "    acuratete.columns = [\"Dificultate\", f\"Acuratețe {eticheta_set}\"]\n",
    "    return acuratete\n",
    "\n",
    "acuratete_test = calculeaza_acuratete_pe_dificultate(\"rezultate_few-shot-test.csv\", \"Test\")\n",
    "acuratete_val  = calculeaza_acuratete_pe_dificultate(\"rezultate_few-shot-validation.csv\", \"Validare\")\n",
    "\n",
    "df_comparatie = pd.merge(acuratete_test, acuratete_val, on=\"Dificultate\", how=\"outer\")\n",
    "print(df_comparatie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b64785-18c4-4c33-80a6-9b9a92e338e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acuratete pe capitol pentru test\n",
    "df_test = pd.read_csv(\"rezultate_few-shot-test.csv\")\n",
    "df_all = pd.read_csv(\"exercitii_extrase_structurat_rezolvari.csv\")\n",
    "df_test[\"id\"] = df_test[\"prompt\"].str.extract(r\"^(\\S+)\").iloc[:, 0].str.replace(r\"\\.$\", \"\", regex=True)\n",
    "df_test[\"id\"] = df_test[\"id\"].astype(str)\n",
    "df_all[\"id\"] = df_all[\"id\"].astype(str)\n",
    "df_merged = df_test.merge(df_all[[\"id\", \"capitol\"]], on=\"id\", how=\"left\")\n",
    "if \"correct\" not in df_merged.columns:\n",
    "    df_merged[\"correct\"] = df_merged[\"true\"] == df_merged[\"pred\"]\n",
    "accuracy_by_chapter = df_merged.groupby(\"capitol\")[\"correct\"].mean().reset_index()\n",
    "accuracy_by_chapter.columns = [\"Capitol\", \"Acuratețe\"]\n",
    "print(accuracy_by_chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a4d86-de80-4431-82e3-9845f33f130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acuratete pe capitol pentru validare\n",
    "df_validare = pd.read_csv(\"rezultate_few-shot-validation.csv\")\n",
    "df_all = pd.read_csv(\"exercitii_extrase_structurat_rezolvari.csv\")\n",
    "df_validare[\"id\"] = df_validare[\"prompt\"].str.extract(r\"^(\\S+)\").iloc[:, 0].str.replace(r\"\\.$\", \"\", regex=True)\n",
    "df_validare[\"id\"] = df_validare[\"id\"].astype(str)\n",
    "df_all[\"id\"] = df_all[\"id\"].astype(str)\n",
    "df_merged = df_validare.merge(df_all[[\"id\", \"capitol\"]], on=\"id\", how=\"left\")\n",
    "if \"correct\" not in df_merged.columns:\n",
    "    df_merged[\"correct\"] = df_merged[\"true\"] == df_merged[\"pred\"]\n",
    "accuracy_by_chapter = df_merged.groupby(\"capitol\")[\"correct\"].mean().reset_index()\n",
    "accuracy_by_chapter.columns = [\"Capitol\", \"Acuratețe\"]\n",
    "print(accuracy_by_chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a205bb-eb51-4da7-a33d-43143b098104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confuzie pentru test\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_test = pd.read_csv(\"rezultate_few-shot-test.csv\")\n",
    "cm = confusion_matrix(df_test[\"raspuns_corect\"], df_test[\"pred\"], labels=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"])\n",
    "plt.figure(figsize=(4, 3.5))\n",
    "sns.set(style=\"white\", font_scale=0.9)\n",
    "ax = sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap=\"Blues\",\n",
    "    cbar=True,\n",
    "    linewidths=0.5,\n",
    "    linecolor=\"black\",\n",
    "    xticklabels=list(\"abcdef\"),\n",
    "    yticklabels=list(\"abcdef\"),\n",
    "    annot_kws={\"size\": 10, \"weight\": \"bold\", \"color\": \"black\"}\n",
    ")\n",
    "ax.set_xlabel(\"Predicție\", fontsize=10)\n",
    "ax.set_ylabel(\"Adevărat\", fontsize=10)\n",
    "ax.set_title(\"Matrice de confuzie – set Test\", fontsize=11, weight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"matrice_confuzie_test.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeb7a8d-7d73-4c68-8c58-6f288b04632e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confuzie pentru validare\n",
    "df_validare = pd.read_csv(\"rezultate_few-shot-validation.csv\")\n",
    "cm = confusion_matrix(df_validare[\"raspuns_corect\"], df_validare[\"pred\"], labels=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"])\n",
    "plt.figure(figsize=(4, 3.5))\n",
    "sns.set(style=\"white\", font_scale=0.9)\n",
    "ax = sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap=\"Blues\",\n",
    "    cbar=True,\n",
    "    linewidths=0.5,\n",
    "    linecolor=\"black\",\n",
    "    xticklabels=list(\"abcdef\"),\n",
    "    yticklabels=list(\"abcdef\"),\n",
    "    annot_kws={\"size\": 10, \"weight\": \"bold\", \"color\": \"black\"}\n",
    ")\n",
    "ax.set_xlabel(\"Predicție\", fontsize=10)\n",
    "ax.set_ylabel(\"Adevărat\", fontsize=10)\n",
    "ax.set_title(\"Matrice de confuzie – set Validare\", fontsize=11, weight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"matrice_confuzie_validare.png\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
