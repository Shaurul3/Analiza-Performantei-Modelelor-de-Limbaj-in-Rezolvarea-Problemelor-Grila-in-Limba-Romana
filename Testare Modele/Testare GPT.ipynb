{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde335ea-c6ba-46b0-aeeb-e24633c544ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "    # Incarcare shots\n",
    "def incarca_shots(cale_fisier):\n",
    "    if cale_fisier is None:\n",
    "        return []\n",
    "    with open(cale_fisier, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "    # Cautarea raspunsului corect\n",
    "def extrage_raspuns_corect(text):\n",
    "    match = re.search(r\"[Rr]ăspuns\\s+corect\\s*:\\s*[^a-zA-Z]*([a-fA-F])\", text)\n",
    "    if not match:\n",
    "        match = re.search(r\"\\\\boxed\\{([a-fA-F])\\}\", text)\n",
    "    return match.group(1).lower() if match else \"?\"\n",
    "\n",
    "    # Functia de evaluare a modelului\n",
    "def evalueaza_modelul(test_file_path, model_name, api_key, label=\"Set\", output_csv=True, shots_file=None):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    with open(test_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        test_data = [json.loads(line) for line in f]\n",
    "\n",
    "    shots = incarca_shots(shots_file)\n",
    "\n",
    "    # Pregatirea shot-urilor ca o lista\n",
    "    shots_messages = []\n",
    "    for shot in shots:\n",
    "        shots_messages.extend(shot[\"messages\"])\n",
    "\n",
    "    has_system = any(m[\"role\"] == \"system\" for m in shots_messages)\n",
    "\n",
    "    # Pregatirea setului de date pt incarcare\n",
    "    \n",
    "    true_labels = []\n",
    "    user_prompts = []\n",
    "    assistant_outputs = []\n",
    "\n",
    "    for sample in test_data:\n",
    "        user_prompt = sample[\"messages\"][1][\"content\"]\n",
    "        assistant_answer = sample[\"messages\"][2][\"content\"]\n",
    "        true_label = extrage_raspuns_corect(assistant_answer)\n",
    "\n",
    "        user_prompts.append(user_prompt)\n",
    "        true_labels.append(true_label)\n",
    "        assistant_outputs.append(assistant_answer)\n",
    "\n",
    "    # Rularea modelului  \n",
    "\n",
    "    pred_labels = []\n",
    "    prompturi_generate = []\n",
    "    raspunsuri_generate = []\n",
    "\n",
    "    for prompt in tqdm(user_prompts, desc=f\"Evaluare {label}\"):\n",
    "        try:\n",
    "            prompt_instr = prompt.strip() + \"\\n\\nInstrucțiuni: Alege litera răspunsului corect (a–f). Răspunde exact în formatul: Răspuns corect: x\"\n",
    "            messages = []\n",
    "\n",
    "            if not has_system:\n",
    "                messages.append({\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Ești un asistent care rezolvă exerciții de matematică pentru admitere și oferă explicații clare.\"\n",
    "                })\n",
    "\n",
    "            messages.extend(shots_messages)\n",
    "            messages.append({\"role\": \"user\", \"content\": prompt_instr})\n",
    "\n",
    "            prompt_text = \"\\n\".join([f\"{m['role']}: {m['content']}\" for m in messages])\n",
    "            prompturi_generate.append(prompt_text)\n",
    "\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=messages\n",
    "            )\n",
    "            reply = response.choices[0].message.content\n",
    "            raspunsuri_generate.append(reply)\n",
    "\n",
    "            predicted = extrage_raspuns_corect(reply)\n",
    "            pred_labels.append(predicted if predicted else \"?\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Eroare:\", e)\n",
    "            pred_labels.append(\"?\")\n",
    "            raspunsuri_generate.append(\"Eroare\")\n",
    "            prompturi_generate.append(prompt_text if 'prompt_text' in locals() else \"N/A\")\n",
    "\n",
    "    # Extragerea tuturor informatiilor de la prompt si le aranjam \n",
    "    \n",
    "    df_results = pd.DataFrame({\n",
    "        \"prompt_original\": user_prompts,\n",
    "        \"prompt_model\": prompturi_generate,\n",
    "        \"output\": raspunsuri_generate,\n",
    "        \"true\": true_labels,\n",
    "        \"pred\": pred_labels\n",
    "    })\n",
    "    df_results[\"correct\"] = df_results[\"true\"] == df_results[\"pred\"]\n",
    "\n",
    "    # Date si rapoarte\n",
    "\n",
    "    acc = accuracy_score(df_results[\"true\"], df_results[\"pred\"])\n",
    "    print(f\"\\nAcuratețe ({label}): {acc:.2%}\")\n",
    "    print(\"\\n=== Raport ===\")\n",
    "    print(classification_report(df_results[\"true\"], df_results[\"pred\"], zero_division=0))\n",
    "\n",
    "    # Grafic\n",
    "    toate_literele = list(\"abcdef\")\n",
    "    true_counts = df_results[\"true\"].value_counts().reindex(toate_literele, fill_value=0)\n",
    "    correct_counts = df_results[df_results[\"correct\"]].groupby(\"true\")[\"correct\"].count().reindex(toate_literele, fill_value=0)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(true_counts.index, true_counts.values, alpha=0.5, label=\"Total\")\n",
    "    plt.bar(correct_counts.index, correct_counts.values, alpha=0.8, label=\"Corecte\")\n",
    "    plt.title(f\"Performanță GPT ({label})\")\n",
    "    plt.xlabel(\"Variantă de răspuns\")\n",
    "    plt.ylabel(\"Număr\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if output_csv:\n",
    "        csv_name = f\"rezultate_{label.lower().replace(' ', '_')}.csv\"\n",
    "        df_results.to_csv(csv_name, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"Rezultatele au fost salvate în: {csv_name}\")\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4597637d-35fd-47ad-aee7-e34fa23410fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setari\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\"Chei.env\") # Chei\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY1\")\n",
    "MODEL_NAME = \"gpt-4.1\" #modele: GPT-3.5-turbo, GPT-4.1, modele gpt fine-tunate etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cd8cc2-eac0-4c25-b8e4-4abd37c15468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testare pe setul de test\n",
    "rez_test = evalueaza_modelul(\"fine_tune_full/fine_tune_test_full.jsonl\", MODEL_NAME, API_KEY, label=\"Few-shot-test\", shots_file=\"few-shots.jsonl\")\n",
    "# Label - influentez numele fisierelor la iesire\n",
    "# shots-file = None sau fisierul care are shots-urile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75129c4-c1c6-40a6-8f2f-813197a9033f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testare pe setul de validare\n",
    "rez_valid = evalueaza_modelul(\"fine_tune_full/fine_tune_validation_full.jsonl\", MODEL_NAME, API_KEY, label=\"Few-shot-validation\", shots_file=\"few-shots.jsonl\")\n",
    "# Label - influentez numele fisierelor la iesire\n",
    "# shots-file = None sau fisierul care are shots-urile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c45eaf-5e02-43cf-92bc-525983a651b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acuratete pe seturi\n",
    "acc_valid = rez_valid[\"correct\"].mean()\n",
    "acc_test = rez_test[\"correct\"].mean()\n",
    "\n",
    "print(f\"Acuratețe Validare: {acc_valid:.2%}\")\n",
    "print(f\"Acuratețe Test:     {acc_test:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c451760c-98e4-4713-b8b1-564ab79de7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculez acuratetea pe dificultate pentru fiecare set\n",
    "import pandas as pd\n",
    "\n",
    "def calculeaza_acuratete_pe_dificultate(cale_csv, eticheta_set):\n",
    "    df = pd.read_csv(cale_csv)\n",
    "\n",
    "    # Extrag dificultatea din inceputul promptului\n",
    "    df[\"dificultate\"] = df[\"prompt_original\"].str.extract(r\"\\d+\\.(?:\\d+)?([ABC])\\.\")\n",
    "\n",
    "    # Calculez corectitudinea\n",
    "    if \"correct\" not in df.columns:\n",
    "        df[\"correct\"] = df[\"true\"] == df[\"pred\"]\n",
    "\n",
    "    # Acuratete pe fiecare dificultate\n",
    "    acuratete = df.groupby(\"dificultate\")[\"correct\"].mean().reset_index()\n",
    "    acuratete.columns = [\"Dificultate\", f\"Acuratețe {eticheta_set}\"]\n",
    "\n",
    "    return acuratete\n",
    "\n",
    "acuratete_test = calculeaza_acuratete_pe_dificultate(\"rezultate_few-shot-test.csv\", \"Test\")\n",
    "acuratete_val  = calculeaza_acuratete_pe_dificultate(\"rezultate_few-shot-validation.csv\", \"Validare\")\n",
    "\n",
    "# Comparare\n",
    "df_comparatie = pd.merge(acuratete_test, acuratete_val, on=\"Dificultate\", how=\"outer\")\n",
    "print(df_comparatie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb098be-9204-49ad-9c25-f16bf6d866ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acuratete pe capitol pentru test\n",
    "import pandas as pd\n",
    "\n",
    "df_test = pd.read_csv(\"rezultate_few-shot-test.csv\")\n",
    "df_all = pd.read_csv(\"exercitii_extrase_structurat_rezolvari.csv\")\n",
    "\n",
    "# Extrag ID-ul din începutul promptului si elimin punctul final\n",
    "df_test[\"id\"] = df_test[\"prompt_original\"].str.extract(r\"^(\\S+)\").iloc[:, 0].str.replace(r\"\\.$\", \"\", regex=True)\n",
    "\n",
    "# Asigur tipul string pentru merge\n",
    "df_test[\"id\"] = df_test[\"id\"].astype(str)\n",
    "df_all[\"id\"] = df_all[\"id\"].astype(str)\n",
    "\n",
    "# Adaug coloana 'capitol' prin merge\n",
    "df_merged = df_test.merge(df_all[[\"id\", \"capitol\"]], on=\"id\", how=\"left\")\n",
    "\n",
    "# Calculeaza corectitudinea \n",
    "if \"correct\" not in df_merged.columns:\n",
    "    df_merged[\"correct\"] = df_merged[\"true\"] == df_merged[\"pred\"]\n",
    "\n",
    "# Acuratete pe capitol\n",
    "accuracy_by_chapter = df_merged.groupby(\"capitol\")[\"correct\"].mean().reset_index()\n",
    "accuracy_by_chapter.columns = [\"Capitol\", \"Acuratețe\"]\n",
    "\n",
    "# Rezultate\n",
    "print(accuracy_by_chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc0bf9e-2b25-4daf-98a3-49315187d2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acuratete pe capitol pentru validare\n",
    "import pandas as pd\n",
    "\n",
    "df_test = pd.read_csv(\"rezultate_few-shot-validation.csv\")\n",
    "df_all = pd.read_csv(\"exercitii_extrase_structurat_rezolvari.csv\")\n",
    "\n",
    "# Extrag ID-ul din începutul promptului si elimin punctul final\n",
    "df_test[\"id\"] = df_test[\"prompt_original\"].str.extract(r\"^(\\S+)\").iloc[:, 0].str.replace(r\"\\.$\", \"\", regex=True)\n",
    "\n",
    "# Asigur tipul string pentru merge\n",
    "df_test[\"id\"] = df_test[\"id\"].astype(str)\n",
    "df_all[\"id\"] = df_all[\"id\"].astype(str)\n",
    "\n",
    "# Adaug coloana 'capitol' prin merge\n",
    "df_merged = df_test.merge(df_all[[\"id\", \"capitol\"]], on=\"id\", how=\"left\")\n",
    "\n",
    "# Calculeaza corectitudinea \n",
    "if \"correct\" not in df_merged.columns:\n",
    "    df_merged[\"correct\"] = df_merged[\"true\"] == df_merged[\"pred\"]\n",
    "\n",
    "# Acuratete pe capitol\n",
    "accuracy_by_chapter = df_merged.groupby(\"capitol\")[\"correct\"].mean().reset_index()\n",
    "accuracy_by_chapter.columns = [\"Capitol\", \"Acuratețe\"]\n",
    "\n",
    "# Rezultate\n",
    "print(accuracy_by_chapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727d5fdf-67b4-4f53-8717-876093bc85b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confuzie pentru testare\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "df_test = pd.read_csv(\"rezultate_few-shot-test.csv\")\n",
    "\n",
    "# Calculeaz matricea de confuzie\n",
    "cm = confusion_matrix(df_test[\"true\"], df_test[\"pred\"], labels=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"])\n",
    "\n",
    "# Setari pentru grafic\n",
    "plt.figure(figsize=(4, 3.5))  # dimensiune mică, bună pentru imprimare\n",
    "sns.set(style=\"white\", font_scale=0.9)\n",
    "\n",
    "# Heatmap\n",
    "ax = sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap=\"Blues\",\n",
    "    cbar=True,\n",
    "    linewidths=0.5,\n",
    "    linecolor=\"black\",\n",
    "    xticklabels=list(\"abcdef\"),\n",
    "    yticklabels=list(\"abcdef\"),\n",
    "    annot_kws={\"size\": 10, \"weight\": \"bold\", \"color\": \"black\"}\n",
    ")\n",
    "\n",
    "# Etichete si titlu\n",
    "ax.set_xlabel(\"Predicție\", fontsize=10)\n",
    "ax.set_ylabel(\"Adevărat\", fontsize=10)\n",
    "ax.set_title(\"Matrice de confuzie – Răspunsuri a–f\", fontsize=11, weight=\"bold\")\n",
    "\n",
    "# Layout si salvare\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"matrice_confuzie_test.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aad978-d635-4a70-a820-a527801c12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de confuzie pentru validare\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "df_test = pd.read_csv(\"rezultate_few-shot-validation.csv\")\n",
    "\n",
    "# Calculeaz matricea de confuzie\n",
    "cm = confusion_matrix(df_test[\"true\"], df_test[\"pred\"], labels=[\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"])\n",
    "\n",
    "# Setari pentru grafic\n",
    "plt.figure(figsize=(4, 3.5))  # dimensiune mică, bună pentru imprimare\n",
    "sns.set(style=\"white\", font_scale=0.9)\n",
    "\n",
    "# Heatmap\n",
    "ax = sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap=\"Blues\",\n",
    "    cbar=True,\n",
    "    linewidths=0.5,\n",
    "    linecolor=\"black\",\n",
    "    xticklabels=list(\"abcdef\"),\n",
    "    yticklabels=list(\"abcdef\"),\n",
    "    annot_kws={\"size\": 10, \"weight\": \"bold\", \"color\": \"black\"}\n",
    ")\n",
    "\n",
    "# Etichete si titlu\n",
    "ax.set_xlabel(\"Predicție\", fontsize=10)\n",
    "ax.set_ylabel(\"Adevărat\", fontsize=10)\n",
    "ax.set_title(\"Matrice de confuzie – Răspunsuri a–f\", fontsize=11, weight=\"bold\")\n",
    "\n",
    "# Layout si salvare\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"matrice_confuzie_validare.png\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
